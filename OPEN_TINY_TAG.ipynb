{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xls_data_files = Path(Path.cwd(),  \"xls_data_files\")\n",
    "pickle_data_files = Path(Path.cwd(),  \"pickle_files\")\n",
    "processed_data_files = Path(Path.cwd(),  \"processed_files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def open_tinytag_xls(file, dir_):\n",
    "    \n",
    "    # parse the XML file\n",
    "    tree = ET.parse(dir_ / file)\n",
    "\n",
    "    # get the root of the XML document\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Define the namespace\n",
    "    ns = {'ss': 'urn:schemas-microsoft-com:office:spreadsheet'}\n",
    "\n",
    "    # Access 'Sheet1'\n",
    "    sheet1 = root.find(\"ss:Worksheet[@ss:Name='Sheet1']\", namespaces=ns)\n",
    "\n",
    "    # To access rows in 'Sheet1'\n",
    "    rows = sheet1.findall('.//ss:Row', namespaces=ns)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for row in rows:\n",
    "        rowData = []\n",
    "        cells = row.findall('.//ss:Cell', namespaces=ns)\n",
    "        for cell in cells:\n",
    "            dataElem = cell.find('.//ss:Data', namespaces=ns)\n",
    "            rowData.append(dataElem.text if dataElem is not None else None)\n",
    "        data.append(rowData)\n",
    "\n",
    "    file_str = str(file)\n",
    "        \n",
    "    if file_str[0] == 'R':\n",
    "        df = pd.DataFrame(data, columns=[\"index\", 'date', \"temp_air\", \"relative_humidity\", 'dew_point']).iloc[5:][['date', \"temp_air\", \"relative_humidity\"]]\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df['temp_air'] = df['temp_air'].astype(float).round(1)\n",
    "        df['relative_humidity'] = df['relative_humidity'].astype(float).round(0)\n",
    "        return df\n",
    "    else:\n",
    "        df = pd.DataFrame(data, columns=[\"index\", 'date', \"temp_air\", \"temp_pulp\"]).iloc[5:][['date', \"temp_air\", \"temp_pulp\"]]\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df['temp_air'] = df['temp_air'].astype(float).round(1)\n",
    "        df['temp_pulp'] = df['temp_pulp'].astype(float).round(1)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in [file for file in xls_data_files.iterdir() if file.is_file()]:\n",
    "    df = open_tinytag_xls(file, xls_data_files)a\n",
    "    pickle_filename = file.stem + '.pickle'\n",
    "    df.to_pickle(pickle_data_files / pickle_filename, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for file in [file.name for file in pickle_data_files.iterdir() if file.is_file()]:\n",
    "    name = file.split('.')[0]\n",
    "    df = pd.read_pickle(pickle_data_files / file, compression='gzip')\n",
    "    # df = df[(df['date'] >= start) & (df['date'] <= end)]\n",
    "    df['hours'] = (df['date'] - df['date'].iloc[0]).dt.total_seconds() / 3600.0\n",
    "    df['hours'] = df['hours'].astype(float).round(2)\n",
    "    df['days'] = (df['date'] - df['date'].iloc[0]).dt.total_seconds() / (3600.0 * 24)\n",
    "    df['days'] = df['days'].astype(float).round(5)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    if len(df[(df['days']  < 1.35) & (df['temp_air']  <= 7.5)]) > 0:\n",
    "        print(name, len(df[(df['days'] < 1.35) & (df['days']  > 1.3) & (df['temp_pulp']  <= 7.5)]))\n",
    "        ax.plot(df['days'], df['temp_air'], label=name)\n",
    "    \n",
    "fig.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_pos = pd.read_excel('logger_positions.xlsx')\n",
    "log_pos['id'] = log_pos['treatment'] + \"_\" + log_pos['location_c'] + \"_\" + log_pos['location_p']\n",
    "log_pos = log_pos.set_index('logger')['id']\n",
    "log_pos = log_pos.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = pd.Timestamp(2023, 4, 26, 23, 45)\n",
    "end = pd.Timestamp(2023, 5, 29, 9, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in [file.name for file in pickle_data_files.iterdir() if file.is_file()]:\n",
    "    name = file.split('.')[0]\n",
    "    df = pd.read_pickle(pickle_data_files / file), compression='gzip')\n",
    "    df = df[(df['date'] >= start) & (df['date'] <= end)]\n",
    "    df['hours'] = (df['date'] - df['date'].iloc[0]).dt.total_seconds() / 3600.0\n",
    "    df['hours'] = df['hours'].astype(float).round(2)\n",
    "    df['days'] = (df['date'] - df['date'].iloc[0]).dt.total_seconds() / (3600.0 * 24)\n",
    "    df['days'] = df['days'].astype(float).round(5)\n",
    "    # \n",
    "    \n",
    "    if log_pos[name][:5] == 'CN_M_':\n",
    "        try: df['offset_temp_air'] = df['temp_air']\n",
    "        except: print(log_pos[name])\n",
    "        try: df['offset_temp_pulp'] = df['temp_pulp']\n",
    "        except: print(log_pos[name])\n",
    "        \n",
    "    if log_pos[name][:5] == 'CN_B_':\n",
    "        try: df['offset_temp_air'] = df['temp_air'] - 1\n",
    "        except: print(log_pos[name])\n",
    "        try: df['offset_temp_pulp'] = df['temp_pulp'] - 1\n",
    "        except: print(log_pos[name])\n",
    "        \n",
    "    if log_pos[name][:5] == 'U2_M_':\n",
    "        try: df['offset_temp_air'] = df['temp_air']\n",
    "        except: print(log_pos[name])\n",
    "        try: df['offset_temp_pulp'] = df['temp_pulp']\n",
    "        except: print(log_pos[name])\n",
    "        \n",
    "    if log_pos[name][:5] == 'U2_B_':\n",
    "        try: df['offset_temp_air'] = df['temp_air'] - 1\n",
    "        except: pass\n",
    "        try: df['offset_temp_pulp'] = df['temp_pulp'] - 1 \n",
    "        except: pass\n",
    "        \n",
    "    try:\n",
    "        df.to_pickle(processed_data_files / log_pos[name] + '.pickle', compression='gzip')\n",
    "    except: print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
